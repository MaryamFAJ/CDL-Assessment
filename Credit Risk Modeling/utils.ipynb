{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8c5a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0094eb15-7d23-4f54-b6e4-75396da3cf6d",
   "metadata": {},
   "source": [
    "# Utils Script\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2db0058-cee2-441c-8418-c5139690fd83",
   "metadata": {},
   "source": [
    "### This script consists of the different utility functions for the  credit risk model development \n",
    "### The Functions do a range of tasks from \n",
    "\n",
    "    - Plot graphs \n",
    "    - Create extensive analytical tables \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb5c4fe3-4e0f-4541-91ec-2b20ebd91483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Util Libraries successfully imported\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import datetime as dt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import re\n",
    "import string \n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Util Libraries successfully imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c691a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bce2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to calculate WOE and IV for numerical features\n",
    "def woe_num(data, feature, gbflag):\n",
    "    dt = pd.crosstab(index=data[feature], columns=data[gbflag])\n",
    "    dt['Freq'] = dt.sum(axis=1)\n",
    "    dt['Percentage'] = round((dt['Freq']/dt['Freq'].sum() *100),1)\n",
    "    dt['% Good'] = round((dt['Good']/dt['Good'].sum() *100), 1)\n",
    "    dt['% Bad'] = round((dt['Bad']/dt['Bad'].sum() *100), 1)\n",
    "    dt['Bad Rate'] = round((dt['Bad']/dt['Freq']) *100, 1)\n",
    "    dt['GoodBaddOdds'] = round(dt['Good']/dt['Bad'], 2)\n",
    "    dt['WOE'] = np.log(dt['% Good']/dt['% Bad'])\n",
    "    dt['IV'] = (dt['% Good']- dt['% Bad']) * dt['WOE']\n",
    "#     dt['IV'] = ((dt['% Good']- dt['% Bad']) * dt['WOE']).sum()\n",
    "   # dt = dt.sort_values(['WOE'])\n",
    "    \n",
    "    return dt\n",
    "# Function to calculate WOE and IV for categorical variables\n",
    "# Function to calculate WOE and IV for categorical variables\n",
    "def woe_cat(data, feature, gbflag):\n",
    "    dt = pd.crosstab(index=data[feature], columns=data[gbflag])\n",
    "    dt['Freq'] = dt.sum(axis=1)\n",
    "    dt['Proptn'] = dt['Freq']/dt['Freq'].sum()\n",
    "    dt['% Good'] = dt['Good']/dt['Good'].sum() \n",
    "    dt['% Bad'] = dt['Bad']/dt['Bad'].sum()\n",
    "    dt['Bad Rate'] = dt['Bad']/dt['Freq'] \n",
    "    dt['GoodBaddOdds'] = round(dt['Good']/dt['Bad'], 2)\n",
    "    dt['WOE'] = np.log(dt['% Bad']/dt['% Good'])  # Ratio of Event to Non-Event\n",
    "    dt['class IV'] = (dt['% Bad']-dt['% Good']) * dt['WOE']  # IV for each class/categpry\n",
    "    dt['Variable IV'] = ((dt['% Bad']-dt['% Good']) * dt['WOE']).sum() #IV for the variable\n",
    "    dt = dt.sort_values(['WOE'])\n",
    "    \n",
    "    return dt\n",
    "# A function to get all variables WOE and IV\n",
    "def woe_iv(df, variablie_list, GBFlag):   \n",
    "    output = {}\n",
    "    for variable in variablie_list:\n",
    "        try:\n",
    "            var = woe_cat(df, variable, GBFlag)\n",
    "            \n",
    "            for i in range(len(var.index.values)):\n",
    "                output.setdefault('Variables',[]).append(variable)\n",
    "                output.setdefault('Categories',[]).append(var.index.values[i])\n",
    "                output.setdefault('WOE',[]).append(var['WOE'].values[i])\n",
    "                output.setdefault('IV',[]).append(var['IV'].values[i])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    return pd.DataFrame(output)\n",
    "# woe_iv(data_universe_fai, data_universe_fai_cat.columns, 'GBFlag')\n",
    "# A function that automates and return CA report\n",
    "def Export_CA_Report(df, variablie_list, GBFlag, fileName='CA_Report'):\n",
    "    \n",
    "    # This inner function estimates WoE and IV which represent CA for all the provided variables\n",
    "    def CA_Report(df, variablie_list, GBFlag):\n",
    "        # Create a dictionary to track CA iteratively\n",
    "        output = {}\n",
    "        for variable in variablie_list:\n",
    "            # use the function for estimating WoE for categorical variables to \n",
    "            var = woe_cat(df, variable, GBFlag)\n",
    "            # append to dictionary\n",
    "            output[variable]=var        \n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n",
    "   # Instatiate above function to CA report for all provvided variables\n",
    "    ca_result = CA_Report(df, variablie_list, GBFlag)\n",
    "    # save CA report to Excel\n",
    "    with pd.ExcelWriter(fileName +'.xlsx', engine=\"openpyxl\") as writer:\n",
    "        for variable_name, data in ca_result.items():\n",
    "            data.to_excel(writer, sheet_name=variable_name)\n",
    "    \n",
    "    \n",
    "def fill_binned_nan_values(df, variablie_list, GBFlag):\n",
    "    for variable in variablie_list:\n",
    "        if df[variable].isna().sum() > 0:\n",
    "            # Run CA(WoE & IV) on variable\n",
    "            run_ca = woe_num(df, variable, GBFlag)\n",
    "            # get index value(bin class) of category with least woe\n",
    "            bin_class = run_ca[run_ca['WOE']==max(run_ca['WOE'])].index.values[0]\n",
    "            df[variable] = df[variable].fillna(bin_class)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8febc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f073dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_zero_values_table(df):\n",
    "  \n",
    "    \"\"\"\n",
    "    function for data audit, returns the count and percentage of missing and o values in each column\n",
    "     %% parameters \n",
    "\n",
    "    df: [dataframe] \n",
    "    \n",
    "    \"\"\"\n",
    "  \n",
    "    zero_val = (df == 0.00).astype(int).sum(axis=0)\n",
    "        \n",
    "    zero_val_percent = (df == 0.00).astype(int).sum(axis=0) / len(df)\n",
    "        \n",
    "    mis_val = df.isnull().sum()\n",
    "    \n",
    "    mis_val_percent = round(df.isnull().sum() / len(df),1)\n",
    "    \n",
    "    mz_table = pd.concat([zero_val,zero_val_percent, mis_val, mis_val_percent], axis=1)\n",
    "    \n",
    "    mz_table = mz_table.rename(\n",
    "                                columns = {0 : 'No of 0s', 1 : '% of 0s', 2: 'No of Missing Values', 3 : '% of Missing Values'})\n",
    "    \n",
    "    mz_table['Rows'] = len(df)\n",
    "    mz_table['No of Unique'] = df.nunique()\n",
    "    \n",
    "    mz_table['Data Type'] = df.dtypes\n",
    "    \n",
    "    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns and \" + str(df.shape[0]) + \" Rows.\\n\"      \n",
    "        \"There are \" + str(mz_table.shape[0]) +\n",
    "            \" columns that have missing values.\")\n",
    "    \n",
    "#         mz_table.to_excel('D:/sampledata/missing_and_zero_values.xlsx', freeze_panes=(1,0), index = False)\n",
    "    return mz_table\n",
    "\n",
    "\n",
    "def audit(data):\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    for col in data.columns:\n",
    "        No_unique = data[col].nunique()\n",
    "        Missing = data[col].isna().sum()\n",
    "        perc_missing = Missing/data.shape[0]\n",
    "        Zeros = data[data[col] == 0].shape[0]\n",
    "        perc_zeros = Zeros/data.shape[0]\n",
    "        row_count = data[col].shape[0]\n",
    "        \n",
    "        result.setdefault('Variable', []).append(col)\n",
    "        result.setdefault('No of Unique', []).append(No_unique)\n",
    "        result.setdefault('No of Missing', []).append(Missing)\n",
    "        result.setdefault('% Missing', []).append(perc_missing)\n",
    "        result.setdefault('No of Zeros', []).append(Zeros)\n",
    "        result.setdefault('% Zeros', []).append(perc_zeros)\n",
    "        result.setdefault('No of Rows', []).append(row_count)\n",
    "        \n",
    "    res = pd.DataFrame(result)\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec509949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "\n",
    "\n",
    "def display_side_by_side(*args):\n",
    "    html_str = ''\n",
    "    for df in args:\n",
    "        html_str += df.to_html()\n",
    "    display_html(html_str.replace(\n",
    "        'table', 'table style=\"display:inline\"'), raw=True)\n",
    "    \n",
    "    \n",
    "def sample_first_prows(data, perc=0.8):\n",
    "    '''function to get specified percentage of first rows in the dataframe\n",
    "    '''\n",
    "    return data.head(int(len(data)*(perc)))\n",
    "\n",
    "# train = sample_first_prows(data)\n",
    "# test = data.iloc[max(train.index):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73100766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_binned_nan_values(df, variablie_list, GBFlag):\n",
    "    for variable in variablie_list:\n",
    "        ## Coarse NaN group into the worst woe group if not more than 10% of total data shape\n",
    "      \n",
    "            # Run CA(WoE & IV) on variable using the woe_num function\n",
    "            run_ca = woe_num(df, variable, GBFlag)\n",
    "            # get index value(bin class) of category with worst woe category\n",
    "            bin_class = run_ca[run_ca['WOE']==max(run_ca['WOE'])].index.values[0]\n",
    "            df[variable] = df[variable].fillna(bin_class)\n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eb4a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_woe(df_with_selected_variables):\n",
    "    '''\n",
    "    This function replaces each category in the selected columns with\n",
    "    their woe\n",
    "    \n",
    "    df_with_selected_variables :: Dataframe containing grouped/binned selected\n",
    "    variables\n",
    "    \n",
    "    grpd_variables_woe_iv :: Dataframe containing WoE and IV of grouped/binned\n",
    "    variables\n",
    "    \n",
    "    Note:: Make sure woe_iv function has returned it's result before running\n",
    "    this function. result in this case - grpd_variables_woe_iv\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for variable in df_with_selected_variables.columns:\n",
    "        for category in df_with_selected_variables[variable].unique():\n",
    "            \n",
    "            try:\n",
    "                ### Get WoE from the dataframe running the WoE_IV function\n",
    "                woe =variables_woe_iv[\n",
    "                    (variables_woe_iv['Variables']==variable) & \n",
    "                    (variables_woe_iv['Categories']==category)\n",
    "                ]['WOE'].values[0]\n",
    "\n",
    "                ### Replace each category with their respective woe\n",
    "                df_with_selected_variables[variable] = df_with_selected_variables[variable].replace(category, woe)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "    return df_with_selected_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd185f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A function to get all variables WOE and IV\n",
    "def woe_iv(df, variablie_list, GBFlag):   \n",
    "    output = {}\n",
    "    for variable in variablie_list:\n",
    "        try:\n",
    "            var = woe_cat(df, variable, GBFlag)\n",
    "            \n",
    "            for i in range(len(var.index.values)):\n",
    "                output.setdefault('Variables',[]).append(variable)\n",
    "                output.setdefault('Categories',[]).append(var.index.values[i])\n",
    "                output.setdefault('WOE',[]).append(var['WOE'].values[i])\n",
    "                output.setdefault('Variable IV',[]).append(var['Variable IV'].values[i])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    return pd.DataFrame(output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# A function to get all variables WOE and IV\n",
    "def woe_iv(df, variablie_list, GBFlag):   \n",
    "    output = {}\n",
    "    for variable in variablie_list:\n",
    "        try:\n",
    "            var =  (pd.crosstab(df[variable],df[GBFlag],normalize='columns').assign(woe=lambda dfx: np.log(dfx['Bad'] / dfx['Good'])).assign(iv=lambda dfx: np.sum(dfx['woe']*(dfx['Bad']-dfx['Good']))))\n",
    "            \n",
    "            for i in range(len(var.index.values)):\n",
    "                output.setdefault('Variables',[]).append(variable)\n",
    "                output.setdefault('Categories',[]).append(var.index.values[i])\n",
    "                output.setdefault('WOE',[]).append(var['woe'].values[i])\n",
    "                output.setdefault('Variable IV',[]).append(var['iv'].values[i])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    return pd.DataFrame(output)\n",
    "\n",
    "def iv(df, variablie_list, GBFlag):   \n",
    "    output = {}\n",
    "    for variable in variablie_list:\n",
    "        try:\n",
    "            var = woe_cat(df, variable, GBFlag)\n",
    "            \n",
    "            for i in range(len(var.index.values)):\n",
    "                output.setdefault('Variables',[]).append(variable)\n",
    "                output.setdefault('Variable IV',[]).append(var['Variable IV'].values[i])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    return pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fcae88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function helps in computing Gini from AUC\n",
    "\n",
    "\n",
    "#https://stackoverflow.com/questions/66679372/how-does-the-predict-function-of-statsmodels-interact-with-roc-auc-score-of-scik\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "def compute_gini(y_test, y_train, test_preds, train_preds):\n",
    "    # instantiate roc auc score from sci-kit learn metrics and compute AUC\n",
    "\n",
    "    Test_AUC = roc_auc_score(y_test, test_preds)\n",
    "    Train_AUC = roc_auc_score(y_train, train_preds)\n",
    "    # Compute Gini from AUC\n",
    "    Test_Gini = (2*Test_AUC) - 1\n",
    "    Train_Gini = (2*Train_AUC) - 1\n",
    "    return Test_Gini, Train_Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall(y_test, y_train, test_preds, train_preds):\n",
    "    # instantiate roc auc score from sci-kit learn metrics and compute AUC\n",
    "    train_preds = train_preds.to_list()\n",
    "    train_preds = np.asarray(train_preds)\n",
    "    test_preds = test_preds.to_list()\n",
    "    test_preds = np.asarray(test_preds)\n",
    "    Test_precision, Test_recall, thresh = precision_recall_curve(y_test, test_preds)\n",
    "    Train_precision, Train_recall, train_thresh = precision_recall_curve(y_train, train_preds)\n",
    "\n",
    "    return Test_recall, Train_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision(y_test, y_train, test_preds, train_preds):\n",
    "    # instantiate roc auc score from sci-kit learn metrics and compute AUC\n",
    "    train_preds = train_preds.to_list()\n",
    "    train_preds = np.asarray(train_preds)\n",
    "    test_preds = test_preds.to_list()\n",
    "    test_preds = np.asarray(test_preds)\n",
    "    Test_precision, Test_recall, thresh = precision_recall_curve(y_test, test_preds)\n",
    "    Train_precision, Train_recall, train_thresh = precision_recall_curve(y_train, train_preds)\n",
    "\n",
    "    return Test_precision, Train_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65234ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_woe(df_WoE, rotation_of_x_axis_labels = 0):\n",
    "    x = np.array(df_WoE.index).astype(str)\n",
    "    y = df_WoE['WOE']\n",
    "    plt.figure(figsize = (26, 8))\n",
    "    plt.plot(x, y, marker = 'o', linestyle = '--', color = 'k')\n",
    "    #plt.xlabel(x)\n",
    "    plt.ylabel('Weight of Evidence')\n",
    "    plt.title(str(''))\n",
    "    plt.xticks(rotation = rotation_of_x_axis_labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "974f694f54a02f493e12eb6b1cb55f7f9224502eeb4003e7f82b2e996b0d3812"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('clv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
